## Data Preprocessor

This Python module is designed to clean Telegram JSON data and prepare it for Large Language Model (LLM) training.

### Project Structure

```bash

│
├── data/
│   ├── parsed/
│   │   ├── TIKVAH.csv  # Parsed data file (generated by your parsing tool)
│   │   └── ...         # Other parsed data files
│   ├── cleaned/
│   │   ├── TIKVAH.csv  # Cleaned data file (generated by the script)
│   │   ├── TIKVAH.txt  # Cleaned text file (generated by the script)
│   │   └── ...         # Other cleaned data files
│   └── raw/             # Raw data (if applicable)
│       └── ...
│
│── data_processing
│   ├── cleaningdata.py         # Utility functions (if applicable)
│   └── parsing data.py
│
├── scripts/
├   ├── __init__.py
│   ├── util.py         # Utility functions (if applicable)
│   └── text_cleaner_script.py  # Main script for cleaning data
│
├── README.md           # Project documentation
└── requirements.txt    # List of required Python packages
```

### Usage

1. Ensure your raw data is stored in the data/raw/ directory as specified in the project structure.

2. Open a terminal and navigate to the data_processing directory:

```bash
    cd data_processing
```

3. Run the script to parse the raw data

```bash
    python parsingdata.py
```

4. Run the script to clean the parsed data:

```bash
    python cleaningdata.py
```

This will generate cleaned CSV and TXT files in the data/cleaned/ directory, which can be used for further processing or LLM training
